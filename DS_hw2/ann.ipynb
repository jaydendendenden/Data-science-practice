{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import warnings\n",
    "import csv\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing, metrics, decomposition, pipeline, dummy\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go2\n",
    "import math\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from statistics import mean\n",
    "from sklearn import feature_selection as fs\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_precessed.csv\")\n",
    "df_test = pd.read_csv(\"test_precessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>col_10</th>\n",
       "      <th>col_11</th>\n",
       "      <th>col_12</th>\n",
       "      <th>col_14</th>\n",
       "      <th>col_15</th>\n",
       "      <th>col_16</th>\n",
       "      <th>col_18</th>\n",
       "      <th>col_19</th>\n",
       "      <th>col_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>8557.39</td>\n",
       "      <td>797.115833</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.64</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1767.29</td>\n",
       "      <td>25.400823</td>\n",
       "      <td>143</td>\n",
       "      <td>13.168404</td>\n",
       "      <td>91.952879</td>\n",
       "      <td>264.590301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>19718.92</td>\n",
       "      <td>1676.243333</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.02</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2057.56</td>\n",
       "      <td>28.642449</td>\n",
       "      <td>197</td>\n",
       "      <td>64.066440</td>\n",
       "      <td>107.668408</td>\n",
       "      <td>285.889485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>32045.78</td>\n",
       "      <td>2677.481667</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.19</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1333.18</td>\n",
       "      <td>30.053861</td>\n",
       "      <td>76</td>\n",
       "      <td>169.770374</td>\n",
       "      <td>62.681178</td>\n",
       "      <td>285.296615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>62976.28</td>\n",
       "      <td>5321.023333</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.05</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.66</td>\n",
       "      <td>40.661773</td>\n",
       "      <td>191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.780837</td>\n",
       "      <td>711.321496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>57818.72</td>\n",
       "      <td>4864.226667</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.09</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2348.77</td>\n",
       "      <td>37.882655</td>\n",
       "      <td>174</td>\n",
       "      <td>73.709570</td>\n",
       "      <td>395.136222</td>\n",
       "      <td>307.576874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85264</th>\n",
       "      <td>41</td>\n",
       "      <td>9795.07</td>\n",
       "      <td>586.255833</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>62</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.01</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2065.27</td>\n",
       "      <td>34.916611</td>\n",
       "      <td>67</td>\n",
       "      <td>42.605317</td>\n",
       "      <td>43.529548</td>\n",
       "      <td>242.490718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85266</th>\n",
       "      <td>46</td>\n",
       "      <td>110607.09</td>\n",
       "      <td>8997.257500</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1174.05</td>\n",
       "      <td>24.781202</td>\n",
       "      <td>265</td>\n",
       "      <td>154.824136</td>\n",
       "      <td>232.178801</td>\n",
       "      <td>752.722813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85267</th>\n",
       "      <td>50</td>\n",
       "      <td>96275.84</td>\n",
       "      <td>8101.986667</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.94</td>\n",
       "      <td>5.0</td>\n",
       "      <td>999.36</td>\n",
       "      <td>28.339005</td>\n",
       "      <td>321</td>\n",
       "      <td>64.961337</td>\n",
       "      <td>129.831967</td>\n",
       "      <td>855.405363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85268</th>\n",
       "      <td>55</td>\n",
       "      <td>69388.26</td>\n",
       "      <td>5543.355000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>819.98</td>\n",
       "      <td>40.497795</td>\n",
       "      <td>266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>184.212607</td>\n",
       "      <td>640.122893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85269</th>\n",
       "      <td>40</td>\n",
       "      <td>26738.26</td>\n",
       "      <td>2058.188333</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.85</td>\n",
       "      <td>7.0</td>\n",
       "      <td>828.93</td>\n",
       "      <td>29.985336</td>\n",
       "      <td>74</td>\n",
       "      <td>86.263356</td>\n",
       "      <td>16.606857</td>\n",
       "      <td>342.948620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69754 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       col_1      col_3        col_4  col_5  col_6  col_7  col_8  col_9  \\\n",
       "0         22    8557.39   797.115833      8      6     22      2     37   \n",
       "1         37   19718.92  1676.243333     10      9     19      6     27   \n",
       "2         33   32045.78  2677.481667      6      9     30      7     10   \n",
       "3         42   62976.28  5321.023333      0      3     12      0      9   \n",
       "4         39   57818.72  4864.226667      7      7     21      2     56   \n",
       "...      ...        ...          ...    ...    ...    ...    ...    ...   \n",
       "85264     41    9795.07   586.255833      7      8     29      6     62   \n",
       "85266     46  110607.09  8997.257500      4      4      2      3      2   \n",
       "85267     50   96275.84  8101.986667      6      6     19      1      7   \n",
       "85268     55   69388.26  5543.355000      2      4      6      0      8   \n",
       "85269     40   26738.26  2058.188333      7      6     20      6     10   \n",
       "\n",
       "       col_10  col_11  col_12   col_14     col_15  col_16      col_18  \\\n",
       "0        15.0    7.64     7.0  1767.29  25.400823     143   13.168404   \n",
       "1        11.0   13.02    13.0  2057.56  28.642449     197   64.066440   \n",
       "2        10.0   17.19    11.0  1333.18  30.053861      76  169.770374   \n",
       "3         0.0    6.05     3.0    68.66  40.661773     191    0.000000   \n",
       "4        16.0    4.09    12.0  2348.77  37.882655     174   73.709570   \n",
       "...       ...     ...     ...      ...        ...     ...         ...   \n",
       "85264    19.0    4.01    15.0  2065.27  34.916611      67   42.605317   \n",
       "85266     9.0    4.26     6.0  1174.05  24.781202     265  154.824136   \n",
       "85267    18.0    2.94     5.0   999.36  28.339005     321   64.961337   \n",
       "85268     1.0   14.16     2.0   819.98  40.497795     266    0.000000   \n",
       "85269    13.0   18.85     7.0   828.93  29.985336      74   86.263356   \n",
       "\n",
       "           col_19      col_21  \n",
       "0       91.952879  264.590301  \n",
       "1      107.668408  285.889485  \n",
       "2       62.681178  285.296615  \n",
       "3       70.780837  711.321496  \n",
       "4      395.136222  307.576874  \n",
       "...           ...         ...  \n",
       "85264   43.529548  242.490718  \n",
       "85266  232.178801  752.722813  \n",
       "85267  129.831967  855.405363  \n",
       "85268  184.212607  640.122893  \n",
       "85269   16.606857  342.948620  \n",
       "\n",
       "[69754 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label = df['CreditScore']\n",
    "df_data = df.drop('CreditScore', axis=1) \n",
    "df_data = df_data.iloc[:,:17]\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain , xtest , ytrain , ytest = train_test_split(df_data,df_label,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "xtrain = sc.fit_transform(xtrain)\n",
    "xtest = sc.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JIYAO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units=11, kernel_initializer='uniform', activation='relu', input_dim=17))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units=11, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 846us/step - accuracy: 0.1747 - loss: -107.3056\n",
      "Epoch 2/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 798us/step - accuracy: 0.1725 - loss: -2528.8582\n",
      "Epoch 3/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 803us/step - accuracy: 0.1906 - loss: -10316.4355\n",
      "Epoch 4/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 965us/step - accuracy: 0.2007 - loss: -25060.1055\n",
      "Epoch 5/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 996us/step - accuracy: 0.2039 - loss: -53571.2188\n",
      "Epoch 6/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 938us/step - accuracy: 0.1932 - loss: -89730.8672\n",
      "Epoch 7/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.2147 - loss: -137503.8125\n",
      "Epoch 8/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 962us/step - accuracy: 0.2141 - loss: -223811.4844\n",
      "Epoch 9/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 993us/step - accuracy: 0.2383 - loss: -300879.8438\n",
      "Epoch 10/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 955us/step - accuracy: 0.2183 - loss: -398414.8750\n",
      "Epoch 11/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 993us/step - accuracy: 0.2352 - loss: -546897.5625\n",
      "Epoch 12/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 992us/step - accuracy: 0.2484 - loss: -696026.8125\n",
      "Epoch 13/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.2444 - loss: -894734.5625\n",
      "Epoch 14/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.2167 - loss: -1113276.7500\n",
      "Epoch 15/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 986us/step - accuracy: 0.2671 - loss: -1306283.3750\n",
      "Epoch 16/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.2451 - loss: -1691017.3750\n",
      "Epoch 17/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 997us/step - accuracy: 0.2475 - loss: -1934401.7500\n",
      "Epoch 18/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.2618 - loss: -2321436.0000\n",
      "Epoch 19/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 981us/step - accuracy: 0.2451 - loss: -2800017.0000\n",
      "Epoch 20/100\n",
      "\u001b[1m5581/5581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.2532 - loss: -3161683.5000\n",
      "Epoch 21/100\n",
      "\u001b[1m2693/5581\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.2425 - loss: -4121063.5000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JIYAO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\JIYAO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:325\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 325\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[0;32m    327\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    328\u001b[0m     )\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\JIYAO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\JIYAO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\JIYAO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\JIYAO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JIYAO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\JIYAO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\JIYAO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\JIYAO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\JIYAO\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier.fit(xtrain, ytrain, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m436/436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model:  0.24557379399326212\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(ytest, y_pred.round())\n",
    "sns.heatmap(cm,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False)\n",
    "#accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "ac=accuracy_score(ytest, y_pred.round())\n",
    "print('accuracy of the model: ',ac)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
